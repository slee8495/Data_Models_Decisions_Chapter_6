---
title: New Location Selection on CroqPain restaurant chain
author: Sangho Lee
date: 2023-12-28
output: html_notebook
---

<br>

<br>

### Michel's Task: Finding the Best 10 New Locations Using Regression Analysis with Data from 60 Existing Locations

### I have a dataset containing information on 60 locations, described as follows:

## Croq'Pain

Data on store earnings and other characteristics for the Croq'Pain case. There should be a total of 60 different stores and 10 potential new outlets. The model used for forecasting should be built on data for the existing 60 stores.

### Variables

-   STOR: Store ID
-   CITY: City in the which store is located. Only provided for potential new outlets
-   EARN: Earnings in \$1,000. Operating earnings: annual sales minus annual operating costs. Operating costs exclude the fixed costs of property rent and equipment rental (all capital equipment is purchased by headquarters and rented to the stores). Operating costs include variable costs such as salaries, utilities, supplies, inventories and other expenses.
-   K: Capital invested in the store in \$1,000. This amount is exactly equal to the purchase price of the property (or the lease, in some cases) plus the cost of all equipment and the cost of remodeling the space.
-   SIZE: Size of store in square meters: Total area inside the store
-   EMPL: Number of employees. Not determined until store is opened
-   P15: Number of 15-24 year olds in a 3 km radius around site in 1,000s
-   P25: Number of 25-34 year olds in a 3 km radius around site 1,000s
-   P35: Number of 35-44 year olds in a 3 km radius around site 1,000s
-   P45: Number of 45-54 year olds in a 3 km radius around site 1,000s
-   P55: Number of persons above 55 in a 3 km radius around site 1,000s
-   total: Total population in 3 km radius around site 1,000s
-   INC: Average income in \$1,000 in town or neighborhood around site
-   COMP: Number of competitors in a 1 km radius around site. Establishments considered as competitors include fast food restaurants, bars and cafes equipped providing lunch service
-   NCOMP: Number of restaurants that do not compete directly with CroqPain in 1 km radius around site
-   NREST: Number of non-restaurant businesses in 1 km radius around site
-   PRICE: Monthly rent per square meter of the retail properties in the same locale.
-   CLI = Cost of Living Index. Measures the cost of living in the immediate vicinity to the restaurant site. Aggregate of average cost of living index determined by the commerce department and additional economic measures taken by experts on site
-   CITY: City name for potential new locations

### Now, I will generate a correlation table to examine the relevance of each data point to the "EARN" column, which is our target variable for prediction.

Before analyzing the data, let's load the necessary packages in both R.

#### Load R Packages (R)

```{r, message = FALSE}
library(tidyverse)
library(arrow)
library(reticulate)
library(DT)
library(GGally)
library(readr)
library(MASS)
library(gridExtra)
library(patchwork)
library(car)
library(broom)

```

#### Read the data provided (R)

```{r, include = FALSE}
croqpain <- arrow::read_parquet("CroqPain.parquet")


```

```{r}
croqpain %>% 
    DT::datatable(options = list(scrollX = TRUE))
```

<br> <br>

### Before fitting a linear model, itâ€™s crucial to ensure that the data distribution is suitable for such analysis. By examining histograms and scatter plots, I aim to verify if the data are normally distributed, thus minimizing potential bias caused by outliers.

```{r, message = FALSE}
selected_columns <- c('EARN', 'K', 'SIZE', 'EMPL', 'total', 'P15', 'P25', 'P35', 'P45', 'P55', 'INC', 'PRICE', 'CLI')
plots <- list()

# Loop through selected columns and create a histogram for each
for (i in seq_along(selected_columns)) {
    col <- selected_columns[i]
    p <- ggplot(croqpain, aes_string(col)) +
        geom_histogram(bins = 15, na.rm = TRUE, fill = "steelblue", color = "black") +
        theme_classic() +
        ggtitle(col)
    plots[[i]] <- p
}

invisible(lapply(plots, print))
```

### I've observed some skewness in the data and am aiming to transform it into a normal distribution.

```{r, message = FALSE}
# Specify columns to transform
cols_to_transform <- c('EARN', 'K', 'SIZE', 'INC', 'PRICE', 'CLI')

# Isolate the columns to be transformed
df_transformed <- croqpain[cols_to_transform]

# Adding a constant to make all values positive
min_value <- min(df_transformed, na.rm = TRUE)
df_transformed <- df_transformed + abs(min_value)

# Applying log transformation (adding a small value to avoid log(0))
# Using log1p which is log(x + 1) to handle zero values
df_transformed <- log1p(df_transformed)

# Rename the transformed columns to indicate they are transformed
names(df_transformed) <- paste0(names(df_transformed), "_transformed")

# Combine the original and transformed data
croqpain_transformed <- bind_cols(croqpain, df_transformed)

# Create a list to store plots
transformed_plots <- list()

# Plotting histograms after transformation
for (i in seq_along(cols_to_transform)) {
    col_name <- paste0(cols_to_transform[i], "_transformed")
    p <- ggplot(croqpain_transformed, aes_string(col_name)) +
        geom_histogram(bins = 15, na.rm = TRUE, fill = "steelblue", color = "black") +
        theme_classic() +
        ggtitle(paste('Log Transformed', cols_to_transform[i]))
    transformed_plots[[i]] <- p
}

# Print all transformed plots without indices
invisible(lapply(transformed_plots, print))
```

### The K and Price variable is exhibiting right skewness, while the CLI variable shows left skewness. Let's address these issues to achieve a more symmetrical distribution.

```{r}
# Define the columns to transform
cols_to_transform <- c('K', 'PRICE', 'CLI')

# Initialize an empty list to store the plots
plots <- list()

# Iterate over the columns to transform
for (col in cols_to_transform) {
    # Define the new log-transformed column name
    log_col_name <- paste0(col, "_log")

    # Check if the log-transformed variable already exists
    if (!log_col_name %in% names(croqpain)) {
        # If not, create the log-transformed variable
        # Adding a small value (0.01) to avoid log(0)
        croqpain[[log_col_name]] <- log1p(croqpain[[col]] + 0.01)
    }
    
    # Create the histogram for the log-transformed variable
    p <- ggplot(croqpain, aes_string(x = log_col_name)) +
        geom_histogram(bins = 15, fill = "steelblue", color = "black") +
        labs(x = col, y = 'Count', title = paste('Log Transformed', col)) +
        theme_classic()
    plots[[log_col_name]] <- p
}

# Special handling for 'CLI' reflecting and log transformation
if (!"CLI_reflected_log" %in% names(croqpain)) {
    # Reflecting CLI and then applying log transformation
    croqpain$CLI_reflected_log <- log1p(max(croqpain$CLI, na.rm = TRUE) + 1 - croqpain$CLI)
    
    # Create the histogram for 'CLI_reflected_log'
    p_cli <- ggplot(croqpain, aes(x = CLI_reflected_log)) +
        geom_histogram(bins = 15, fill = "steelblue", color = "black") +
        labs(x = 'CLI', y = 'Count', title = 'Reflected Log Transformed CLI') +
        theme_classic()
    plots[['CLI_reflected_log']] <- p_cli
}

# Print the plots
for (plot_name in names(plots)) {
    print(plots[[plot_name]])
}


```

### The CLI variable remains left-skewed; we need to take further steps to correct this skewness.

```{r, message = FALSE}
# Applying a square transformation to 'CLI'
croqpain$CLI_squared <- croqpain$CLI^2

# Create the histogram for the squared 'CLI'
p_squared_cli <- ggplot(croqpain, aes(x = CLI_squared)) +
    geom_histogram(bins = 15, fill = "steelblue", color = "black") +
    labs(x = 'Squared CLI', y = 'Count', title = 'Squared Transformed CLI') +
    theme_classic()

# Print the histogram for squared 'CLI'
print(p_squared_cli)
```

<br>

## To optimize the predictive performance of our linear regression model, we should consider identifying the most influential predictor variables. We can apply a stepwise selection technique or experiment with diverse variable combinations to evaluate their contribution to the model's accuracy.

#### We'll initiate the process with a basic linear regression model and incrementally incorporate additional predictor variables. After each inclusion, we will examine the Adjusted R-squared or an alternative performance metric to determine if the newly added variable enhances the overall model efficacy.

```{r}
# Fit the initial full model
full_model <- lm(EARN ~ ., data=croqpain_transformed %>% dplyr::select(-CITY))

summary(full_model)

```

### **Overall Model Fit:**

-   **Residuals**: The range suggests some large errors in predictions, with residuals as low as -5275.4 and as high as 6234.2. This indicates variability in how well the model fits different observations.

-   **Multiple R-squared**: 0.7762. Approximately 77.62% of the variability in 'EARN' is explained by the model, which is relatively high, suggesting a good fit.

-   **Adjusted R-squared**: 0.6432. This is lower than the Multiple R-squared, considering the number of predictors in the model. It's a more accurate measure of fit, suggesting that some predictors might not be contributing much to the model.

-   **F-statistic**: The F-statistic is 5.834 with a very low p-value (1.412e-06), indicating that the model is statistically significant and that there's a relationship between the predictors and the dependent variable.

### 

## Upon reviewing the model's performance, I have selected the following variables to construct my ultimate linear regression model. The rationale for each choice is detailed below.

### **1. PRICE (Monthly rent per square meter)**

-   **Rationale**: It has a statistically significant relationship with 'EARN' (p = 0.0311) and a positive coefficient, suggesting that stores in areas with higher rent tend to have higher earnings. This could be due to such areas generally being more prosperous or having higher foot traffic.

### **2. INC (Average income in the neighborhood)**

-   **Rationale**: Although not statistically significant at the 0.05 level (p = 0.0685), it's close and has a substantial positive coefficient. Higher average income might mean that residents have more disposable income, potentially leading to higher store earnings.

-   **Consideration**: It's just above the conventional threshold for significance. However, given its practical relevance and close-to-significant p-value, it may still be worth considering, especially in combination with other variables.

### I have crafted the final code to pinpoint optimal new locations by leveraging significant predictors identified from the model, specifically 'PRICE' and 'INC'. Here is the refined implementation:

### 

```{r}
new_locations <- croqpain_transformed %>%
  dplyr::filter(is.na(EARN)) %>%
  dplyr::select(CITY, PRICE, INC)  

# Summarizing the data to find the best locations based on 'PRICE' and 'INC'
best_locations <- new_locations %>%
  dplyr::group_by(CITY) %>%
  dplyr::summarize(
    Average_PRICE = mean(PRICE, na.rm = TRUE),
    Average_INC = mean(INC, na.rm = TRUE)
  ) %>%
  dplyr::arrange(desc(Average_PRICE), desc(Average_INC)) 

# Select the top locations based on the criteria
top_locations <- head(best_locations, 10)  

# View the top locations
top_locations %>% 
  DT::datatable()
```

# Conclusion

### **Key Predictors:**

-   **PRICE (Monthly rent per square meter)**: Statistically significant in the broader model, indicating that areas with higher rent tend to have higher earnings. This might be due to these areas being more affluent or having higher foot traffic.

-   **INC (Average income in the neighborhood)**: Although not statistically significant at the 0.05 level in the broader model, it showed a tendency toward higher earnings in areas with higher average income. This is intuitively appealing as areas with higher income levels might have residents with more disposable income.

### **Potential New Locations:**

The analysis identified ten potential new locations based on the average 'PRICE' and 'INC' of the surrounding area. The top locations are as follows:

1.  **Marseilles-2**: Highest average price among the potential locations and a moderate average income level.

2.  **Calais**: Lower average price compared to Marseilles-2 but with a higher average income, indicating a potentially affluent customer base.

3.  **Aubusson**: Similar price level to Calais but with a slightly lower average income.

4.  **Torcy**: Moderate in both price and income, possibly indicating a balanced market.

5.  **Dijon**: Lower average price with a relatively higher average income, might indicate a cost-effective location with a good customer base.

### **Final Conclusion:**

-   The locations are ranked based on 'PRICE' and 'INC', with the assumption that higher values in these variables might indicate more desirable locations due to the potential for higher earnings.

-   **Marseilles-2** stands out due to its combination of a higher average price and a reasonable average income, suggesting it might be a lucrative area. However, it's also likely to come with higher operational costs.

-   **Calais** and **Dijon** present interesting opportunities with their combination of higher average income levels and moderate prices, which might indicate a good balance between potential earnings and costs.

### 

<br>

<br>
