---
title: " "
toc: false
---

#### Michel's task on finding best new 10 locations challenge will best suited with Regression Analytics when other 60 Locations data is given.

#### I have a dataset with 60 location's information with the description below

## Croq'Pain

Data on store earnings and other characteristics for the Croq'Pain case. There should be a total of 60 different stores and 10 potential new outlets. The model used for forecasting should be built on data for the existing 60 stores.

### Variables

-   STOR: Store ID
-   CITY: City in the which store is located. Only provided for potential new outlets
-   EARN: Earnings in \$1,000. Operating earnings: annual sales minus annual operating costs. Operating costs exclude the fixed costs of property rent and equipment rental (all capital equipment is purchased by headquarters and rented to the stores). Operating costs include variable costs such as salaries, utilities, supplies, inventories and other expenses.
-   K: Capital invested in the store in \$1,000. This amount is exactly equal to the purchase price of the property (or the lease, in some cases) plus the cost of all equipment and the cost of remodeling the space.
-   SIZE: Size of store in square meters: Total area inside the store
-   EMPL: Number of employees. Not determined until store is opened
-   P15: Number of 15-24 year olds in a 3 km radius around site in 1,000s
-   P25: Number of 25-34 year olds in a 3 km radius around site 1,000s
-   P35: Number of 35-44 year olds in a 3 km radius around site 1,000s
-   P45: Number of 45-54 year olds in a 3 km radius around site 1,000s
-   P55: Number of persons above 55 in a 3 km radius around site 1,000s
-   total: Total population in 3 km radius around site 1,000s
-   INC: Average income in \$1,000 in town or neighborhood around site
-   COMP: Number of competitors in a 1 km radius around site. Establishments considered as competitors include fast food restaurants, bars and cafes equipped providing lunch service
-   NCOMP: Number of restaurants that do not compete directly with CroqPain in 1 km radius around site
-   NREST: Number of non-restaurant businesses in 1 km radius around site
-   PRICE: Monthly rent per square meter of the retail properties in the same locale.
-   CLI = Cost of Living Index. Measures the cost of living in the immediate vicinity to the restaurant site. Aggregate of average cost of living index determined by the commerce department and additional economic measures taken by experts on site
-   CITY: City name for potential new locations

## Now I will run the corrlation table to see how each data points has the relavance to "EARN" column which is our gola to predict.

Before we read the data, let me load packages for both R & Python.

#### Load R Packages (R)

```{r, message = FALSE}
library(tidyverse)
library(arrow)
library(reticulate)
library(DT)
library(GGally)
library(readr)

```

#### Load Python Packages (Python)

```{python, message = FALSE}
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import boxcox

```

#### Read the data provided (R)

```{r, include = FALSE}
setwd("/home/jovyan/Desktop/Desktop - Sanghoâ€™s MacBook Pro/Sangho's Business Analytics Project/Chapter 6/Data_Models_Decisions_Chapter_6_the_construction_department_at_croqpain")
croqpain <- arrow::read_parquet("CroqPain.parquet")


```

```{r}
croqpain %>% 
  DT::datatable()
```

```{r, include = FALSE}
# Convert the R dataframe to a Python object
py$croqpain <- r_to_py(croqpain)

```

<br> <br>

### Before I fit a linear model, I would like to make sure the distribution if it's a good data to fit a model by looking at Histogram and Scatter Plots.

#### Creat Histograms (Python)

```{python, message = FALSE}
num_columns = croqpain.select_dtypes(include=['float64', 'int64']).columns

selected_columns = ['EARN', 'K', 'SIZE', 'EMPL', 'total', 'P15', 'P25', 'P35', 'P45', 'P55', 'INC', 'PRICE', 'CLI']

plt.figure(figsize=(20, 15))
for i, col in enumerate(selected_columns, 1):
    plt.subplot(5, 4, i)
    plt.hist(croqpain[col].dropna(), bins=15)
    plt.title(col)

plt.tight_layout()
plt.show()

```

### Here, I see some skewness and want to make them normal distribution.

#### (Python)

```{python, message = FALSE}
# Selecting the relevant columns for transformation
cols_to_transform = ['EARN', 'K', 'SIZE', 'INC', 'PRICE', 'CLI']
df_transformed = croqpain[cols_to_transform].copy()

# Applying log transformation (adding a small value to avoid log(0))
# Using numpy's log1p which is log(x + 1) to handle zero values
df_transformed = np.log1p(df_transformed)

# Plotting histograms after transformation
plt.figure(figsize=(15, 10))
for i, col in enumerate(cols_to_transform, 1):
    plt.subplot(4, 4, i)
    plt.hist(df_transformed[col].dropna(), bins=15)
    plt.title(f'Log Transformed {col}')

plt.tight_layout()
plt.show()

```

<br>

### K, Price is still Right Skewed, and CLI is left skewed. Let's fix that!

```{python, message = FALSE}
# For right-skewed data ('K' and 'PRICE'), Box-Cox transformation
# Box-Cox requires all values to be positive, so add a small value to avoid zero or negative values
df_transformed['K_boxcox'], _ = boxcox(croqpain['K'] + 0.01)  
df_transformed['PRICE_boxcox'], _ = boxcox(croqpain['PRICE'] + 0.01)

# For left-skewed data ('CLI'), we use a reflection (subtracting from a constant) and then log transformation
max_cli = croqpain['CLI'].max() + 1  
df_transformed['CLI_reflected_log'] = np.log(max_cli - croqpain['CLI'])

# Plotting histograms after further transformations
plt.figure(figsize=(15, 5))

# Box-Cox transformed histograms
plt.subplot(1, 3, 1)
plt.hist(df_transformed['K_boxcox'].dropna(), bins=15)
plt.title('Box-Cox Transformed K')

plt.subplot(1, 3, 2)
plt.hist(df_transformed['PRICE_boxcox'].dropna(), bins=15)
plt.title('Box-Cox Transformed PRICE')

# Reflected log transformed histogram
plt.subplot(1, 3, 3)
plt.hist(df_transformed['CLI_reflected_log'].dropna(), bins=15)
plt.title('Reflected Log Transformed CLI')

plt.tight_layout()
plt.show()

```

### Oh, No... CLI is still left skewed

```{python, message = FALSE}
# Applying a square transformation to 'CLI'
df_transformed['CLI_squared'] = croqpain['CLI'] ** 2

# Plotting the histogram for the squared 'CLI'
plt.figure(figsize=(6, 4))
plt.hist(df_transformed['CLI_squared'].dropna(), bins=15)
plt.title('Squared Transformed CLI')
plt.show()

```

### Okay, good. Now we have a normally distributed data points. 
### How about Outliers? Will ther be any outliers to affect the data to be normal? let's look at the scatter plots! 

```{python, message = FALSE, echo = FALSE}
# Scatter plots of EARN against other transformed variables
predictor_columns = ['K', 'SIZE', 'EMPL', 'P15', 'P25', 'P35', 'P45', 'P55', 'total', 'INC', 'PRICE', 'CLI']
num_predictors = len(predictor_columns)
num_rows = (num_predictors + 2) // 3

plt.figure(figsize=(15, num_rows * 5))

for i, col in enumerate(predictor_columns):
    plt.subplot(num_rows, 3, i + 1)
    x_data = df_transformed[col] if col in cols_to_transform else croqpain[col]
    y_data = df_transformed['EARN']  
    plt.scatter(x_data, y_data, alpha=0.5)
    plt.xlabel(f'{"Transformed " if col in cols_to_transform else ""}{col}')
    plt.ylabel('Transformed EARN')
    plt.title(f'EARN vs {"Transformed " if col in cols_to_transform else ""}{col}')

plt.tight_layout()
plt.show()
```

